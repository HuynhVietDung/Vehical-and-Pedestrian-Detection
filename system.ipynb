{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5310,"status":"ok","timestamp":1728587072934,"user":{"displayName":"Dũng Huỳnh","userId":"03031465843101199705"},"user_tz":-420},"id":"QTdCk14-y99H","outputId":"20e88958-2d3d-4e7f-bab4-12d764accc4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/882.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m882.2/882.2 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install ultralytics -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9ssIcLbrr26"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import tensorflow as tf\n","from ultralytics import YOLO\n","\n","class AutonomousVehicleAI:\n","    def __init__(self, yolo_model_path):\n","        # Load the fine-tuned YOLOv8n model for known object detection\n","        self.known_object_model = YOLO(yolo_model_path)\n","\n","        # Load or define an autoencoder for novel object detection\n","        self.novel_object_model = self.build_autoencoder()\n","\n","        # Placeholder for collision avoidance model (or logic)\n","        self.collision_avoidance_model = None\n","\n","    def build_autoencoder(self):\n","        # Build a simple autoencoder for anomaly detection\n","        input_img = tf.keras.layers.Input(shape=(224, 224, 3))\n","\n","        # Encoder\n","        x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n","        x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","        x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","        encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","\n","        # Decoder\n","        x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n","        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","        x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","        decoded = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","        # Compile the model\n","        autoencoder = tf.keras.Model(input_img, decoded)\n","        autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","        return autoencoder\n","\n","    def detect_known_objects(self, frame):\n","        # Perform detection using YOLO\n","        results = self.known_object_model(frame)\n","\n","        # Extract the results\n","        detected_objects = []\n","        for result in results:\n","            for box in result.boxes:  # Each result contains boxes\n","                detected_objects.append({\n","                    'class_id': box.cls.item(),  # Class ID\n","                    'confidence': box.conf.item(),  # Confidence score\n","                    'bbox': box.xyxy[0].cpu().numpy()  # Bounding box coordinates\n","                })\n","\n","        return detected_objects\n","\n","    def detect_novel_objects(self, frame):\n","        # Preprocess the frame\n","        img = cv2.resize(frame, (224, 224))\n","        img = np.expand_dims(img, axis=0) / 255.0  # Normalize the image for autoencoder\n","\n","        # Predict using the autoencoder (reconstruct the image)\n","        reconstructed = self.novel_object_model.predict(img)\n","\n","        # Calculate reconstruction error (Mean Squared Error)\n","        reconstruction_error = np.mean(np.square(img - reconstructed))\n","\n","        # Set a threshold for novelty detection (tune this based on validation set)\n","        novelty_threshold = 0.02\n","\n","        # Detect if the object is novel based on the reconstruction error\n","        if reconstruction_error > novelty_threshold:\n","            return True\n","        else:\n","            return False\n","\n","    def make_collision_avoidance_decision(self, detected_objects, sensor_data):\n","        # collision avoidance logic\n","        for obj in detected_objects:\n","            if isinstance(obj, bool) and obj:  # If novel object detected\n","                print(\"Novel object detected! Taking evasive action.\")\n","                return \"Evasive action taken\"\n","            elif obj['confidence'] > 0.5:  # If high confidence in known object detection\n","                print(f\"Known object detected: {obj['class_id']} with confidence {obj['confidence']}\")\n","\n","        # Use sensor data for additional decisions (e.g., slowing down, stopping)\n","        if sensor_data.get(\"distance_to_object\", 100) < 10:\n","            return \"Slowing down or stopping\"\n","\n","        return \"Proceed with caution\"\n","\n","    def process_frame(self, frame, sensor_data):\n","        # Detect known objects\n","        known_objects = self.detect_known_objects(frame)\n","\n","        # Detect novel objects\n","        novel_object_detected = self.detect_novel_objects(frame)\n","\n","        # Combine the known and novel objects\n","        decision = self.make_collision_avoidance_decision(known_objects + [novel_object_detected], sensor_data)\n","\n","        return decision"]},{"cell_type":"markdown","source":["### Example code usage"],"metadata":{"id":"pOvaziZ45jkM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23472,"status":"ok","timestamp":1728587148505,"user":{"displayName":"Dũng Huỳnh","userId":"03031465843101199705"},"user_tz":-420},"id":"tudkLO100kaI","outputId":"315350d6-8b44-4f55-b620-95c8596f82e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10587,"status":"ok","timestamp":1728587189074,"user":{"displayName":"Dũng Huỳnh","userId":"03031465843101199705"},"user_tz":-420},"id":"gUgc2ldY0eYh","outputId":"e7d28763-603b-4019-f242-a604ecad370a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","0: 640x640 (no detections), 7.3ms\n","Speed: 81.7ms preprocess, 7.3ms inference, 139.7ms postprocess per image at shape (1, 3, 640, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n"]}],"source":["# Initialize your AI system with the path to the fine-tuned YOLOv8n model\n","vehicle_ai = AutonomousVehicleAI('/content/drive/MyDrive/Colab Notebooks/Interview Test/yolov8n-kitti/train/weights/best.pt')\n","\n","# Example frame and sensor data\n","frame = np.random.rand(224, 224, 3) * 255\n","sensor_data = {\"distance_to_object\": 8}\n","\n","# Process the frame and make a decision\n","decision = vehicle_ai.process_frame(frame, sensor_data)\n","print(\"Decision:\", decision)"]},{"cell_type":"markdown","source":["## Example video input"],"metadata":{"id":"xdsDH6Mt5xhe"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"V2rR-agqyZdO","outputId":"5f4010d0-427b-4852-bf4e-e3d11ba35199"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\n","0: 384x640 (no detections), 18.0ms\n","Speed: 4.9ms preprocess, 18.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.0ms\n","Speed: 3.9ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.2ms\n","Speed: 9.2ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 3.4ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.5ms\n","Speed: 6.9ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.4ms\n","Speed: 3.3ms preprocess, 20.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.6ms\n","Speed: 4.8ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 5.2ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.4ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 3.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.2ms\n","Speed: 5.2ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.9ms\n","Speed: 3.4ms preprocess, 24.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 9.6ms\n","Speed: 3.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.1ms\n","Speed: 9.3ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.8ms\n","Speed: 3.4ms preprocess, 30.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.7ms\n","Speed: 6.7ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.2ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.5ms\n","Speed: 4.1ms preprocess, 28.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.0ms\n","Speed: 3.3ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.3ms\n","Speed: 4.3ms preprocess, 24.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.2ms preprocess, 20.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.7ms\n","Speed: 3.3ms preprocess, 22.7ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.4ms\n","Speed: 3.2ms preprocess, 17.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.9ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.3ms\n","Speed: 3.2ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.1ms\n","Speed: 3.3ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 29.0ms\n","Speed: 11.0ms preprocess, 29.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.2ms\n","Speed: 3.2ms preprocess, 19.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.5ms\n","Speed: 3.4ms preprocess, 23.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.3ms\n","Speed: 6.2ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.5ms\n","Speed: 3.9ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 4.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.7ms\n","Speed: 3.2ms preprocess, 18.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.5ms\n","Speed: 5.3ms preprocess, 18.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.2ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.3ms\n","Speed: 4.7ms preprocess, 21.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.0ms\n","Speed: 5.1ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 29.1ms\n","Speed: 3.3ms preprocess, 29.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.4ms\n","Speed: 4.0ms preprocess, 12.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 4.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.2ms\n","Speed: 7.4ms preprocess, 20.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.0ms\n","Speed: 3.4ms preprocess, 21.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.4ms\n","Speed: 8.8ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.7ms\n","Speed: 3.3ms preprocess, 21.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.8ms\n","Speed: 3.3ms preprocess, 27.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.1ms\n","Speed: 3.2ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.1ms\n","Speed: 8.3ms preprocess, 19.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.9ms\n","Speed: 3.2ms preprocess, 22.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.1ms\n","Speed: 7.5ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.1ms\n","Speed: 5.3ms preprocess, 16.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.9ms\n","Speed: 9.7ms preprocess, 21.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.8ms\n","Speed: 11.5ms preprocess, 24.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.3ms\n","Speed: 3.5ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.8ms\n","Speed: 3.4ms preprocess, 14.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.2ms\n","Speed: 7.2ms preprocess, 16.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.3ms\n","Speed: 3.3ms preprocess, 20.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.4ms\n","Speed: 3.4ms preprocess, 20.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.3ms\n","Speed: 4.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 3.3ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.8ms\n","Speed: 5.5ms preprocess, 20.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 5.0ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.6ms\n","Speed: 5.0ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.6ms\n","Speed: 3.8ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.0ms\n","Speed: 3.6ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.0ms\n","Speed: 4.6ms preprocess, 16.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.5ms\n","Speed: 4.0ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.7ms\n","Speed: 3.4ms preprocess, 21.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.4ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 4.8ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.1ms\n","Speed: 3.3ms preprocess, 21.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.0ms\n","Speed: 7.3ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 29.4ms\n","Speed: 3.4ms preprocess, 29.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.6ms\n","Speed: 3.3ms preprocess, 21.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 4.8ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.2ms\n","Speed: 5.1ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.4ms\n","Speed: 3.4ms preprocess, 24.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.9ms\n","Speed: 3.3ms preprocess, 19.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.3ms\n","Speed: 3.2ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 3.4ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 5.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 4.3ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.2ms preprocess, 20.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 14.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.7ms\n","Speed: 3.6ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.6ms\n","Speed: 3.5ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.6ms\n","Speed: 6.4ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.6ms\n","Speed: 3.7ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.5ms\n","Speed: 3.3ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.8ms\n","Speed: 6.9ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.2ms\n","Speed: 3.4ms preprocess, 30.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.1ms\n","Speed: 3.3ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.6ms\n","Speed: 6.4ms preprocess, 21.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.4ms\n","Speed: 5.7ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.9ms\n","Speed: 4.3ms preprocess, 16.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.8ms\n","Speed: 4.9ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.6ms\n","Speed: 3.3ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.6ms\n","Speed: 3.3ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.5ms\n","Speed: 9.3ms preprocess, 25.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.2ms\n","Speed: 3.5ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.7ms\n","Speed: 3.4ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.1ms\n","Speed: 7.5ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.2ms\n","Speed: 3.3ms preprocess, 19.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.3ms\n","Speed: 3.2ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.9ms\n","Speed: 3.3ms preprocess, 21.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.8ms\n","Speed: 3.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.0ms\n","Speed: 3.5ms preprocess, 16.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.2ms\n","Speed: 3.3ms preprocess, 14.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 3.6ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.4ms\n","Speed: 6.0ms preprocess, 27.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.2ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.6ms\n","Speed: 3.2ms preprocess, 23.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.1ms\n","Speed: 7.1ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.9ms\n","Speed: 8.4ms preprocess, 19.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.2ms\n","Speed: 3.3ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.7ms\n","Speed: 4.2ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.0ms\n","Speed: 3.4ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.9ms\n","Speed: 3.6ms preprocess, 18.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.3ms\n","Speed: 7.4ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 7.2ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.3ms\n","Speed: 9.6ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.1ms\n","Speed: 3.3ms preprocess, 21.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 8.7ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.6ms\n","Speed: 10.5ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.6ms\n","Speed: 3.3ms preprocess, 19.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.2ms\n","Speed: 14.6ms preprocess, 19.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.5ms\n","Speed: 6.1ms preprocess, 23.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.8ms\n","Speed: 8.8ms preprocess, 22.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.0ms\n","Speed: 4.7ms preprocess, 19.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.3ms preprocess, 20.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.0ms\n","Speed: 7.5ms preprocess, 18.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 9.7ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.1ms\n","Speed: 3.3ms preprocess, 28.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 9.5ms preprocess, 17.1ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.6ms\n","Speed: 7.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.2ms\n","Speed: 3.1ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.4ms\n","Speed: 4.0ms preprocess, 20.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.0ms\n","Speed: 14.4ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.6ms\n","Speed: 7.7ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 32.7ms\n","Speed: 10.3ms preprocess, 32.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.5ms\n","Speed: 3.4ms preprocess, 24.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.9ms\n","Speed: 4.1ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.3ms\n","Speed: 6.8ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 3.7ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.2ms\n","Speed: 3.3ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.1ms\n","Speed: 3.6ms preprocess, 19.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.5ms\n","Speed: 3.3ms preprocess, 23.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.6ms\n","Speed: 6.2ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.2ms\n","Speed: 3.3ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.3ms\n","Speed: 3.3ms preprocess, 30.3ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.3ms\n","Speed: 3.3ms preprocess, 26.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.6ms\n","Speed: 3.3ms preprocess, 18.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 3.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.3ms\n","Speed: 7.1ms preprocess, 20.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 5.6ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.1ms\n","Speed: 4.4ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.9ms\n","Speed: 3.4ms preprocess, 30.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 20.8ms\n","Speed: 3.2ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 11.3ms\n","Speed: 3.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.3ms\n","Speed: 3.7ms preprocess, 23.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 5.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.5ms\n","Speed: 4.1ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.4ms\n","Speed: 3.4ms preprocess, 24.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 1 Truck, 21.1ms\n","Speed: 4.4ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 20.6ms\n","Speed: 4.4ms preprocess, 20.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.9ms\n","Speed: 3.4ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.8ms\n","Speed: 3.6ms preprocess, 10.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.3ms\n","Speed: 6.1ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.0ms\n","Speed: 4.7ms preprocess, 30.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 20.9ms\n","Speed: 3.4ms preprocess, 20.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 11.3ms\n","Speed: 3.4ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 11.3ms\n","Speed: 7.0ms preprocess, 11.3ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.4ms\n","Speed: 3.3ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 17.5ms\n","Speed: 6.2ms preprocess, 17.5ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 11.3ms\n","Speed: 3.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 3.2ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.9ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.3ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.4ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.9ms\n","Speed: 3.3ms preprocess, 26.9ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 3.2ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.3ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 3.5ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.0ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.6ms\n","Speed: 3.4ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 23.5ms\n","Speed: 4.8ms preprocess, 23.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 27.5ms\n","Speed: 3.3ms preprocess, 27.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 14.6ms\n","Speed: 3.6ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Van, 19.1ms\n","Speed: 3.4ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 3.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.5ms\n","Speed: 3.3ms preprocess, 16.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.4ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.4ms\n","Speed: 4.4ms preprocess, 16.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.1ms\n","Speed: 3.5ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 3.9ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 17.6ms\n","Speed: 6.2ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 19.0ms\n","Speed: 6.8ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.1ms\n","Speed: 4.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.5ms\n","Speed: 3.3ms preprocess, 18.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.1ms\n","Speed: 3.3ms preprocess, 22.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.6ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.4ms\n","Speed: 4.7ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.9ms\n","Speed: 6.8ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 4.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.3ms preprocess, 20.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.6ms\n","Speed: 3.4ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.6ms\n","Speed: 3.4ms preprocess, 21.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.2ms\n","Speed: 6.9ms preprocess, 20.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.3ms\n","Speed: 3.2ms preprocess, 21.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.9ms\n","Speed: 3.4ms preprocess, 25.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.2ms\n","Speed: 5.5ms preprocess, 30.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.7ms\n","Speed: 3.3ms preprocess, 20.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.9ms\n","Speed: 4.3ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 13.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 4.2ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 5.2ms preprocess, 18.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.9ms\n","Speed: 3.3ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.1ms\n","Speed: 3.5ms preprocess, 16.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.4ms\n","Speed: 3.2ms preprocess, 18.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 29.3ms\n","Speed: 3.4ms preprocess, 29.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.3ms\n","Speed: 6.5ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.8ms\n","Speed: 3.2ms preprocess, 16.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.9ms\n","Speed: 3.2ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.2ms preprocess, 20.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.8ms\n","Speed: 3.3ms preprocess, 20.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 3.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 7.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.5ms\n","Speed: 3.4ms preprocess, 20.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 6.2ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.4ms\n","Speed: 3.4ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.0ms\n","Speed: 3.7ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.6ms\n","Speed: 3.2ms preprocess, 25.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.6ms\n","Speed: 3.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.3ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.9ms\n","Speed: 4.0ms preprocess, 21.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 4.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.5ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 4.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 34.2ms\n","Speed: 3.3ms preprocess, 34.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.7ms\n","Speed: 3.3ms preprocess, 19.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 4.0ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.7ms\n","Speed: 3.6ms preprocess, 26.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.1ms\n","Speed: 6.3ms preprocess, 22.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 3.5ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.5ms\n","Speed: 8.4ms preprocess, 18.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.3ms\n","Speed: 2.9ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.1ms\n","Speed: 3.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.5ms\n","Speed: 3.6ms preprocess, 20.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 5.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 3.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 4.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 3.7ms preprocess, 9.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.6ms\n","Speed: 3.2ms preprocess, 25.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 5.6ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.8ms\n","Speed: 4.0ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.4ms\n","Speed: 4.4ms preprocess, 20.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.3ms\n","Speed: 3.3ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 3.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 6.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 4.1ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.7ms\n","Speed: 6.2ms preprocess, 22.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 4.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 4.2ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 4.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.8ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 31.2ms\n","Speed: 3.3ms preprocess, 31.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.9ms\n","Speed: 3.3ms preprocess, 19.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.3ms\n","Speed: 3.4ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.7ms\n","Speed: 3.4ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.9ms\n","Speed: 3.4ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.3ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.1ms\n","Speed: 4.2ms preprocess, 24.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 3.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.4ms\n","Speed: 7.4ms preprocess, 20.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.7ms\n","Speed: 5.9ms preprocess, 27.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.9ms\n","Speed: 3.3ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.3ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.4ms\n","Speed: 3.4ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.1ms\n","Speed: 3.4ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.9ms\n","Speed: 3.5ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.1ms\n","Speed: 3.3ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.4ms preprocess, 20.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.6ms\n","Speed: 4.3ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 3.4ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.2ms\n","Speed: 3.5ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.1ms\n","Speed: 3.3ms preprocess, 25.1ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.6ms\n","Speed: 4.1ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 4.1ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 21.5ms\n","Speed: 3.4ms preprocess, 21.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 9.7ms\n","Speed: 3.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.2ms\n","Speed: 3.5ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.7ms\n","Speed: 3.3ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 4.3ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 18.3ms\n","Speed: 5.3ms preprocess, 18.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 30.8ms\n","Speed: 3.3ms preprocess, 30.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 22.4ms\n","Speed: 4.5ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.8ms\n","Speed: 3.5ms preprocess, 21.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.2ms\n","Speed: 3.4ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.9ms\n","Speed: 3.4ms preprocess, 19.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 18.4ms\n","Speed: 11.0ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 23.5ms\n","Speed: 4.0ms preprocess, 23.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Known object detected: 3.0 with confidence 0.5756234526634216\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 18.3ms\n","Speed: 3.4ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Known object detected: 3.0 with confidence 0.5818943977355957\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.3ms\n","Speed: 3.3ms preprocess, 27.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.9ms\n","Speed: 3.3ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.5ms\n","Speed: 3.4ms preprocess, 21.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.2ms\n","Speed: 5.7ms preprocess, 18.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.6ms\n","Speed: 8.5ms preprocess, 19.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.3ms\n","Speed: 3.4ms preprocess, 26.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.5ms\n","Speed: 4.6ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.9ms\n","Speed: 5.9ms preprocess, 19.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 34.4ms\n","Speed: 3.3ms preprocess, 34.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.2ms\n","Speed: 3.3ms preprocess, 19.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 3.6ms preprocess, 12.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.7ms\n","Speed: 3.5ms preprocess, 26.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 27.5ms\n","Speed: 3.9ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.1ms\n","Speed: 3.6ms preprocess, 25.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.6ms\n","Speed: 3.4ms preprocess, 20.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.9ms\n","Speed: 7.3ms preprocess, 28.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.3ms\n","Speed: 3.9ms preprocess, 21.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.4ms preprocess, 20.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 19.5ms\n","Speed: 3.7ms preprocess, 19.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.6ms\n","Speed: 3.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.0ms\n","Speed: 4.8ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.2ms\n","Speed: 3.3ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 3.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.8ms\n","Speed: 3.4ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.0ms\n","Speed: 6.5ms preprocess, 23.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.8ms\n","Speed: 3.4ms preprocess, 20.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.0ms\n","Speed: 3.4ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.6ms\n","Speed: 3.2ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Pedestrian, 18.2ms\n","Speed: 3.7ms preprocess, 18.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Pedestrian, 17.0ms\n","Speed: 3.5ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.6ms\n","Speed: 4.1ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.8ms\n","Speed: 9.1ms preprocess, 20.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 3.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.5ms\n","Speed: 5.3ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.5ms\n","Speed: 3.4ms preprocess, 19.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 4.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.9ms\n","Speed: 4.4ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.0ms\n","Speed: 7.3ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.4ms\n","Speed: 7.7ms preprocess, 21.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 3.4ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.2ms\n","Speed: 3.7ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.2ms\n","Speed: 3.3ms preprocess, 23.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 3.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.6ms\n","Speed: 3.9ms preprocess, 22.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.6ms\n","Speed: 8.7ms preprocess, 24.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 10.2ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.3ms preprocess, 20.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 8.4ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.4ms\n","Speed: 7.5ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.0ms\n","Speed: 3.2ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.2ms preprocess, 20.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.3ms\n","Speed: 3.7ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 3.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.5ms\n","Speed: 11.4ms preprocess, 22.5ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.5ms\n","Speed: 3.3ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.5ms\n","Speed: 4.6ms preprocess, 18.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.0ms\n","Speed: 3.5ms preprocess, 25.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.2ms\n","Speed: 3.3ms preprocess, 18.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 3.3ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.2ms\n","Speed: 3.9ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.3ms\n","Speed: 3.2ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.4ms\n","Speed: 3.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.3ms\n","Speed: 10.6ms preprocess, 20.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 3.4ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 5.3ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.9ms\n","Speed: 3.3ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.9ms preprocess, 20.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.4ms\n","Speed: 3.6ms preprocess, 23.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.4ms\n","Speed: 9.5ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.6ms\n","Speed: 4.1ms preprocess, 14.6ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 4.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.0ms\n","Speed: 4.5ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.5ms\n","Speed: 4.9ms preprocess, 23.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.5ms\n","Speed: 4.1ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.9ms\n","Speed: 3.4ms preprocess, 25.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.0ms\n","Speed: 3.4ms preprocess, 18.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.3ms\n","Speed: 3.4ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 3.2ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.4ms\n","Speed: 3.6ms preprocess, 23.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.0ms\n","Speed: 3.4ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.1ms\n","Speed: 6.4ms preprocess, 26.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.6ms\n","Speed: 6.3ms preprocess, 16.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.3ms\n","Speed: 6.7ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.5ms\n","Speed: 3.3ms preprocess, 21.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.8ms\n","Speed: 3.4ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.7ms\n","Speed: 3.3ms preprocess, 19.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 3.3ms preprocess, 15.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.9ms\n","Speed: 3.3ms preprocess, 22.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.7ms\n","Speed: 4.1ms preprocess, 24.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.2ms\n","Speed: 3.5ms preprocess, 22.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.0ms\n","Speed: 3.2ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 3.3ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.8ms\n","Speed: 7.4ms preprocess, 17.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.9ms\n","Speed: 4.8ms preprocess, 14.9ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 3.3ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.5ms\n","Speed: 7.6ms preprocess, 17.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.0ms\n","Speed: 5.2ms preprocess, 17.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.9ms\n","Speed: 3.3ms preprocess, 22.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.8ms\n","Speed: 6.4ms preprocess, 23.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.8ms\n","Speed: 3.4ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.6ms\n","Speed: 4.5ms preprocess, 21.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.8ms\n","Speed: 3.3ms preprocess, 17.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.7ms\n","Speed: 3.3ms preprocess, 14.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.4ms\n","Speed: 4.7ms preprocess, 20.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 3.6ms preprocess, 18.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 41.0ms\n","Speed: 4.4ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.4ms\n","Speed: 11.0ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.5ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.9ms\n","Speed: 3.5ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 31.0ms\n","Speed: 3.5ms preprocess, 31.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 7.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 5.9ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.1ms\n","Speed: 9.4ms preprocess, 14.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.1ms preprocess, 10.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 4.2ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.4ms\n","Speed: 3.8ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.5ms\n","Speed: 3.4ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.2ms\n","Speed: 3.3ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.1ms\n","Speed: 3.3ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.6ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.4ms\n","Speed: 8.7ms preprocess, 25.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 3.3ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.6ms\n","Speed: 9.8ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.9ms\n","Speed: 3.4ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 2 Pedestrians, 11.0ms\n","Speed: 4.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.2ms\n","Speed: 6.2ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.7ms\n","Speed: 3.2ms preprocess, 30.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.3ms\n","Speed: 5.1ms preprocess, 28.3ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.9ms\n","Speed: 3.3ms preprocess, 21.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.5ms\n","Speed: 4.2ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 4.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.1ms\n","Speed: 3.3ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.4ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.9ms\n","Speed: 3.3ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.5ms\n","Speed: 7.8ms preprocess, 19.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.2ms\n","Speed: 3.5ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.9ms\n","Speed: 10.6ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 31.5ms\n","Speed: 3.3ms preprocess, 31.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.2ms\n","Speed: 3.3ms preprocess, 21.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.2ms\n","Speed: 3.3ms preprocess, 30.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.2ms\n","Speed: 3.3ms preprocess, 18.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.9ms\n","Speed: 3.3ms preprocess, 17.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 3.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.5ms\n","Speed: 5.9ms preprocess, 21.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.1ms\n","Speed: 4.4ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.9ms\n","Speed: 3.9ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 6.4ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.2ms\n","Speed: 3.5ms preprocess, 20.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 5.1ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 2.9ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 4.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 9.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.2ms\n","Speed: 3.4ms preprocess, 27.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.2ms\n","Speed: 3.3ms preprocess, 20.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 3.2ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.5ms\n","Speed: 10.7ms preprocess, 30.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 3.6ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.6ms\n","Speed: 6.5ms preprocess, 22.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 5.9ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.5ms\n","Speed: 3.4ms preprocess, 18.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 3.8ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.5ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 33.5ms\n","Speed: 4.7ms preprocess, 33.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 5.2ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.4ms\n","Speed: 3.4ms preprocess, 24.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.4ms\n","Speed: 3.2ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.2ms\n","Speed: 9.5ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Tram, 25.2ms\n","Speed: 7.8ms preprocess, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.7ms\n","Speed: 5.3ms preprocess, 17.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.4ms\n","Speed: 7.4ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.5ms\n","Speed: 3.4ms preprocess, 23.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.7ms\n","Speed: 8.3ms preprocess, 22.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.1ms\n","Speed: 3.3ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.5ms\n","Speed: 3.4ms preprocess, 23.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.2ms\n","Speed: 3.4ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.7ms\n","Speed: 6.3ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.4ms\n","Speed: 3.3ms preprocess, 25.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.4ms\n","Speed: 3.6ms preprocess, 24.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.5ms\n","Speed: 6.0ms preprocess, 17.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.7ms\n","Speed: 3.4ms preprocess, 25.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.3ms\n","Speed: 3.5ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 4.2ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.3ms\n","Speed: 3.3ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.3ms\n","Speed: 6.8ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 5.7ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.7ms\n","Speed: 7.4ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.0ms\n","Speed: 3.3ms preprocess, 15.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.9ms\n","Speed: 3.3ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.4ms\n","Speed: 4.6ms preprocess, 18.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 4.3ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.9ms\n","Speed: 3.3ms preprocess, 27.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 37.3ms\n","Speed: 3.5ms preprocess, 37.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.2ms\n","Speed: 3.4ms preprocess, 30.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.2ms\n","Speed: 3.3ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 4.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.7ms\n","Speed: 5.3ms preprocess, 17.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 3.3ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.3ms\n","Speed: 3.3ms preprocess, 20.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.6ms\n","Speed: 4.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.4ms\n","Speed: 4.9ms preprocess, 25.4ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.3ms\n","Speed: 3.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.3ms\n","Speed: 3.3ms preprocess, 17.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.7ms\n","Speed: 3.3ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 8.3ms preprocess, 15.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.3ms\n","Speed: 4.3ms preprocess, 23.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 3.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 8.0ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.4ms\n","Speed: 3.5ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 3.2ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.0ms\n","Speed: 3.3ms preprocess, 22.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.1ms\n","Speed: 3.4ms preprocess, 21.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.0ms\n","Speed: 4.7ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.7ms\n","Speed: 3.4ms preprocess, 28.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Tram, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.7ms\n","Speed: 3.3ms preprocess, 19.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.3ms\n","Speed: 5.3ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.3ms\n","Speed: 3.5ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 3.8ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 32.3ms\n","Speed: 3.4ms preprocess, 32.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 4.6ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 3.4ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.3ms\n","Speed: 3.3ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.3ms\n","Speed: 8.3ms preprocess, 21.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.6ms\n","Speed: 11.3ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.0ms\n","Speed: 8.5ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 4.0ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.9ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.2ms\n","Speed: 3.4ms preprocess, 12.2ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 4.3ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.7ms\n","Speed: 3.6ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.5ms\n","Speed: 5.8ms preprocess, 14.5ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.0ms\n","Speed: 3.3ms preprocess, 21.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.2ms\n","Speed: 3.4ms preprocess, 19.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 4.3ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.9ms\n","Speed: 4.1ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 3.0ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.8ms\n","Speed: 3.3ms preprocess, 19.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 3.3ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.0ms\n","Speed: 4.0ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 3.5ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.6ms\n","Speed: 3.3ms preprocess, 17.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 11.4ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.2ms\n","Speed: 3.4ms preprocess, 24.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.8ms\n","Speed: 3.3ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 7.0ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 4.5ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.2ms\n","Speed: 3.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.3ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 32.0ms\n","Speed: 3.3ms preprocess, 32.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.0ms\n","Speed: 3.4ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 4.0ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 3.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.0ms\n","Speed: 2.9ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.5ms\n","Speed: 3.4ms preprocess, 21.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.9ms\n","Speed: 7.9ms preprocess, 17.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.3ms\n","Speed: 7.9ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.2ms\n","Speed: 7.4ms preprocess, 28.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.1ms\n","Speed: 3.4ms preprocess, 27.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.4ms\n","Speed: 3.4ms preprocess, 17.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.7ms\n","Speed: 3.5ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.9ms\n","Speed: 5.5ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.2ms\n","Speed: 3.5ms preprocess, 24.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.2ms\n","Speed: 3.5ms preprocess, 20.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.5ms\n","Speed: 3.4ms preprocess, 19.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.7ms\n","Speed: 7.0ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.6ms\n","Speed: 3.4ms preprocess, 24.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.7ms\n","Speed: 3.3ms preprocess, 13.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.3ms\n","Speed: 8.3ms preprocess, 19.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.2ms\n","Speed: 7.4ms preprocess, 21.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.2ms\n","Speed: 4.3ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 4.6ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.4ms\n","Speed: 3.3ms preprocess, 24.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.2ms\n","Speed: 3.3ms preprocess, 19.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.2ms\n","Speed: 3.2ms preprocess, 22.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.8ms\n","Speed: 3.2ms preprocess, 23.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.3ms\n","Speed: 3.2ms preprocess, 23.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.7ms\n","Speed: 3.4ms preprocess, 20.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.3ms\n","Speed: 4.5ms preprocess, 18.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.7ms\n","Speed: 6.2ms preprocess, 21.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.6ms\n","Speed: 3.4ms preprocess, 21.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.7ms\n","Speed: 4.9ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.6ms\n","Speed: 4.9ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.9ms\n","Speed: 4.8ms preprocess, 18.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.8ms\n","Speed: 3.2ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 3.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.2ms\n","Speed: 3.4ms preprocess, 18.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 3.8ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.8ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.1ms\n","Speed: 3.3ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 6.4ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.1ms\n","Speed: 4.5ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.7ms\n","Speed: 4.9ms preprocess, 26.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.7ms\n","Speed: 4.1ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 36.6ms\n","Speed: 5.8ms preprocess, 36.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.4ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 3.3ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.3ms\n","Speed: 3.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 5.0ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.2ms\n","Speed: 3.4ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 24.8ms\n","Speed: 5.1ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Known object detected: 3.0 with confidence 0.5379937291145325\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 6.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 28.1ms\n","Speed: 8.4ms preprocess, 28.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 20.5ms\n","Speed: 7.0ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Known object detected: 3.0 with confidence 0.5904160141944885\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.2ms\n","Speed: 3.5ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Known object detected: 3.0 with confidence 0.5891832709312439\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 21.6ms\n","Speed: 3.2ms preprocess, 21.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Known object detected: 3.0 with confidence 0.6113167405128479\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.4ms\n","Speed: 4.8ms preprocess, 24.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.4ms\n","Speed: 3.5ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Known object detected: 3.0 with confidence 0.5923067331314087\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.1ms preprocess, 20.0ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.1ms\n","Speed: 3.4ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 4.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 11.4ms\n","Speed: 3.3ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Known object detected: 3.0 with confidence 0.5679234862327576\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.3ms\n","Speed: 3.2ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.8ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Misc, 17.5ms\n","Speed: 3.5ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Misc, 10.6ms\n","Speed: 3.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Misc, 20.7ms\n","Speed: 3.4ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.6ms\n","Speed: 3.3ms preprocess, 21.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Misc, 26.7ms\n","Speed: 3.6ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Misc, 11.4ms\n","Speed: 3.5ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Known object detected: 5.0 with confidence 0.5030288100242615\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Misc, 10.0ms\n","Speed: 5.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Known object detected: 5.0 with confidence 0.8042865991592407\n","Known object detected: 3.0 with confidence 0.7877727746963501\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Misc, 28.9ms\n","Speed: 3.3ms preprocess, 28.9ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Known object detected: 5.0 with confidence 0.8273246884346008\n","Known object detected: 3.0 with confidence 0.8138497471809387\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Misc, 12.9ms\n","Speed: 3.3ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Known object detected: 3.0 with confidence 0.7179660797119141\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Misc, 18.8ms\n","Speed: 3.4ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Known object detected: 5.0 with confidence 0.890600323677063\n","Known object detected: 3.0 with confidence 0.7025530934333801\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 16.3ms\n","Speed: 3.4ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Known object detected: 3.0 with confidence 0.8067069053649902\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 11.1ms\n","Speed: 3.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Known object detected: 3.0 with confidence 0.7720439434051514\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Misc, 9.7ms\n","Speed: 4.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Known object detected: 5.0 with confidence 0.5313758254051208\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Misc, 24.4ms\n","Speed: 3.4ms preprocess, 24.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Known object detected: 5.0 with confidence 0.5964794754981995\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Tram, 27.2ms\n","Speed: 4.5ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.0ms\n","Speed: 3.5ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 3.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.8ms\n","Speed: 6.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.1ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.4ms\n","Speed: 3.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.5ms\n","Speed: 3.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.3ms\n","Speed: 9.4ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 3.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.9ms\n","Speed: 3.2ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.2ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.4ms\n","Speed: 4.1ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 14.7ms\n","Speed: 6.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 22.3ms\n","Speed: 3.4ms preprocess, 22.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.4ms\n","Speed: 3.4ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.6ms\n","Speed: 5.5ms preprocess, 28.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.4ms\n","Speed: 3.4ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.3ms\n","Speed: 6.3ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 28.3ms\n","Speed: 3.4ms preprocess, 28.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.1ms\n","Speed: 3.8ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 9.6ms\n","Speed: 3.3ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 25.2ms\n","Speed: 3.4ms preprocess, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 13.9ms\n","Speed: 3.3ms preprocess, 13.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 16.9ms\n","Speed: 3.4ms preprocess, 16.9ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 26.1ms\n","Speed: 3.2ms preprocess, 26.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 20.9ms\n","Speed: 3.6ms preprocess, 20.9ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 24.1ms\n","Speed: 4.0ms preprocess, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.2ms\n","Speed: 3.3ms preprocess, 22.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.1ms\n","Speed: 3.3ms preprocess, 24.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Tram, 23.2ms\n","Speed: 3.2ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 15.7ms\n","Speed: 3.4ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.4ms\n","Speed: 3.3ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.3ms\n","Speed: 3.3ms preprocess, 18.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.6ms\n","Speed: 3.4ms preprocess, 22.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.7ms\n","Speed: 6.3ms preprocess, 20.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Tram, 21.8ms\n","Speed: 7.6ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 23.1ms\n","Speed: 8.7ms preprocess, 23.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 20.5ms\n","Speed: 3.3ms preprocess, 20.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 28.8ms\n","Speed: 3.2ms preprocess, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 26.0ms\n","Speed: 3.3ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 17.0ms\n","Speed: 3.5ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Tram, 19.0ms\n","Speed: 4.1ms preprocess, 19.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 16.3ms\n","Speed: 6.6ms preprocess, 16.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 29.0ms\n","Speed: 3.7ms preprocess, 29.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 12.2ms\n","Speed: 6.7ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Tram, 24.3ms\n","Speed: 3.3ms preprocess, 24.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Tram, 23.3ms\n","Speed: 3.4ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 2 Cyclists, 18.4ms\n","Speed: 3.2ms preprocess, 18.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Known object detected: 3.0 with confidence 0.5633243322372437\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 15.2ms\n","Speed: 6.5ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.2ms\n","Speed: 3.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.7ms\n","Speed: 4.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 30.6ms\n","Speed: 3.4ms preprocess, 30.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 7.9ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 15.3ms\n","Speed: 7.9ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 9.4ms\n","Speed: 3.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Tram, 24.5ms\n","Speed: 7.8ms preprocess, 24.5ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 1 Tram, 25.1ms\n","Speed: 4.7ms preprocess, 25.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 1 Tram, 17.1ms\n","Speed: 3.5ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 18.1ms\n","Speed: 3.9ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 3.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.9ms\n","Speed: 3.6ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 23.7ms\n","Speed: 3.3ms preprocess, 23.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Known object detected: 3.0 with confidence 0.7332453727722168\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 16.8ms\n","Speed: 3.3ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 14.0ms\n","Speed: 3.4ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.6ms\n","Speed: 3.6ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.8ms\n","Speed: 3.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.6ms\n","Speed: 8.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.9ms\n","Speed: 6.3ms preprocess, 16.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 26.8ms\n","Speed: 3.5ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 13.5ms\n","Speed: 6.7ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.6ms\n","Speed: 3.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 16.6ms\n","Speed: 8.6ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.4ms\n","Speed: 3.5ms preprocess, 18.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.8ms\n","Speed: 5.6ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 3.3ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Tram, 13.9ms\n","Speed: 7.4ms preprocess, 13.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.8ms\n","Speed: 7.3ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.5ms\n","Speed: 3.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Tram, 14.1ms\n","Speed: 3.3ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.0ms\n","Speed: 11.4ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 3.3ms preprocess, 9.3ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.4ms\n","Speed: 3.4ms preprocess, 19.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.1ms\n","Speed: 3.3ms preprocess, 25.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 3.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.9ms\n","Speed: 3.3ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.8ms\n","Speed: 10.4ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Tram, 13.0ms\n","Speed: 3.3ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 9.9ms\n","Speed: 4.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 16.3ms\n","Speed: 4.5ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 1 Misc, 15.4ms\n","Speed: 3.4ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Known object detected: 3.0 with confidence 0.7005580067634583\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 11.7ms\n","Speed: 3.3ms preprocess, 11.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Cyclist, 10.8ms\n","Speed: 3.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Known object detected: 3.0 with confidence 0.5392827391624451\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.1ms\n","Speed: 4.8ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.1ms\n","Speed: 4.8ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.7ms\n","Speed: 3.3ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.8ms\n","Speed: 3.8ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.4ms\n","Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.9ms\n","Speed: 3.2ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 31.4ms\n","Speed: 7.5ms preprocess, 31.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.7ms\n","Speed: 3.2ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 4.4ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.0ms\n","Speed: 3.2ms preprocess, 22.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.4ms\n","Speed: 4.3ms preprocess, 18.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 4.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.1ms\n","Speed: 2.9ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 13.5ms\n","Speed: 9.0ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.6ms\n","Speed: 3.3ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.9ms\n","Speed: 4.3ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 17.4ms\n","Speed: 6.4ms preprocess, 17.4ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 9.5ms preprocess, 20.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.2ms preprocess, 20.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.5ms\n","Speed: 11.6ms preprocess, 21.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.8ms\n","Speed: 3.5ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.0ms\n","Speed: 3.1ms preprocess, 20.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.3ms\n","Speed: 3.1ms preprocess, 18.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 29.5ms\n","Speed: 3.2ms preprocess, 29.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.0ms\n","Speed: 6.4ms preprocess, 25.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.8ms\n","Speed: 3.3ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.9ms\n","Speed: 3.7ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.8ms\n","Speed: 5.8ms preprocess, 19.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.7ms\n","Speed: 3.7ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 31.8ms\n","Speed: 7.3ms preprocess, 31.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.7ms\n","Speed: 4.6ms preprocess, 20.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.4ms\n","Speed: 3.3ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.7ms\n","Speed: 3.3ms preprocess, 27.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.7ms\n","Speed: 3.4ms preprocess, 22.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 21.1ms\n","Speed: 3.8ms preprocess, 21.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 25.6ms\n","Speed: 3.3ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.4ms\n","Speed: 3.3ms preprocess, 23.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.3ms\n","Speed: 4.5ms preprocess, 18.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.7ms\n","Speed: 3.4ms preprocess, 23.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 27.7ms\n","Speed: 6.1ms preprocess, 27.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 20.5ms\n","Speed: 3.4ms preprocess, 20.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 24.5ms\n","Speed: 3.4ms preprocess, 24.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.4ms\n","Speed: 6.9ms preprocess, 15.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 23.7ms\n","Speed: 5.1ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 14.0ms\n","Speed: 3.3ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.4ms\n","Speed: 3.4ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 19.6ms\n","Speed: 3.6ms preprocess, 19.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 12.0ms\n","Speed: 3.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 22.3ms\n","Speed: 3.4ms preprocess, 22.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 15.6ms\n","Speed: 3.6ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 26.2ms\n","Speed: 7.9ms preprocess, 26.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 11.7ms\n","Speed: 12.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 4.3ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 10.3ms\n","Speed: 3.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 12.1ms\n","Speed: 3.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 27.0ms\n","Speed: 3.5ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 15.9ms\n","Speed: 3.3ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 18.0ms\n","Speed: 3.3ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Known object detected: 0.0 with confidence 0.595437228679657\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 10.9ms\n","Speed: 4.4ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Known object detected: 0.0 with confidence 0.5874404907226562\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 18.9ms\n","Speed: 3.2ms preprocess, 18.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 10.3ms\n","Speed: 9.3ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 3.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 9.3ms\n","Speed: 3.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n","\n","0: 384x640 1 Car, 11.5ms\n","Speed: 3.4ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","Novel object detected! Taking evasive action.\n","Decision: Evasive action taken\n"]}],"source":["model_path = '/content/drive/MyDrive/Colab Notebooks/Interview Test/yolov8n-kitti/train/weights/best.pt'\n","ai_system = AutonomousVehicleAI(model_path)\n","\n","# Simulating video input (replace with actual video capture)\n","video = cv2.VideoCapture(\"/content/drive/MyDrive/Colab Notebooks/Interview Test/input.mp4\")\n","\n","while True:\n","    ret, frame = video.read()\n","    if not ret:\n","        break\n","\n","    # Simulating sensor data (replace with actual sensor inputs)\n","    sensor_data = {\"distance_to_object\": 8}\n","\n","    decision = ai_system.process_frame(frame, sensor_data)\n","    print(\"Decision:\", decision)\n","\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","video.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}